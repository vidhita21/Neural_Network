{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Neural Network <br> <font size=3.4> Dataset:forestfires.csv<br><font size=2>PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\mruna\\anaconda3\\lib\\site-packages (2.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Layer,Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('forestfires.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking for null values & data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since number of columns are more, let's use PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the data (leaving out the target variable, and the taking only the numerical data for input)\n",
    "df1= df.iloc[:,2:30]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(df1)\n",
    "df_norm = sc.transform(df1)\n",
    "df_norm                     #Normalised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  1.30619034e-14, -1.63267504e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02,  4.68082711e-15, -4.51925684e-16],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  4.39226511e-15, -2.00039593e-16],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01,  3.29069057e-17,  3.06608857e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02,  5.35070622e-16,  1.08857027e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  1.24763181e-16,  7.68823392e-17]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 28)\n",
    "pca_values = pca.fit_transform(df_norm)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 2.12618672e-33])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The amount of variance that each PCA explains is \n",
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cumulative variance \n",
    "var1 = np.cumsum(np.round(var,decimals = 4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variance plot for PCA components obtained\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(var1,color=\"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting first 24 PCAs out of total 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf = pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                     df[['size_category']]], axis = 1)\n",
    "finalDf.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "array = finalDf.values\n",
    "X = array[:,0:24]\n",
    "Y = array[:,24]\n",
    "\n",
    "X.reshape(-1,1)\n",
    "Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 4s 23ms/step - loss: 0.6454 - accuracy: 0.6704 - val_loss: 0.7096 - val_accuracy: 0.6538\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.6072 - accuracy: 0.7147 - val_loss: 0.7130 - val_accuracy: 0.6667\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5822 - accuracy: 0.7479 - val_loss: 0.7167 - val_accuracy: 0.6667\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5652 - accuracy: 0.7618 - val_loss: 0.7063 - val_accuracy: 0.6603\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.5531 - accuracy: 0.7673 - val_loss: 0.7093 - val_accuracy: 0.6603\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.7645 - val_loss: 0.7076 - val_accuracy: 0.6603\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5297 - accuracy: 0.7729 - val_loss: 0.7089 - val_accuracy: 0.6603\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.7756 - val_loss: 0.7060 - val_accuracy: 0.6603\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5129 - accuracy: 0.7756 - val_loss: 0.7076 - val_accuracy: 0.6603\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5055 - accuracy: 0.7812 - val_loss: 0.7096 - val_accuracy: 0.6603\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4986 - accuracy: 0.7784 - val_loss: 0.7054 - val_accuracy: 0.6603\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4908 - accuracy: 0.7812 - val_loss: 0.7017 - val_accuracy: 0.6603\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4842 - accuracy: 0.7812 - val_loss: 0.6999 - val_accuracy: 0.6603\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.7812 - val_loss: 0.7036 - val_accuracy: 0.6603\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.7812 - val_loss: 0.6986 - val_accuracy: 0.6667\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7867 - val_loss: 0.7047 - val_accuracy: 0.6667\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4590 - accuracy: 0.7895 - val_loss: 0.6988 - val_accuracy: 0.6731\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7922 - val_loss: 0.7013 - val_accuracy: 0.6731\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7978 - val_loss: 0.6965 - val_accuracy: 0.6731\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8033 - val_loss: 0.7001 - val_accuracy: 0.6667\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8033 - val_loss: 0.7062 - val_accuracy: 0.6731\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.8033 - val_loss: 0.7122 - val_accuracy: 0.6731\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8061 - val_loss: 0.7075 - val_accuracy: 0.6795\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8089 - val_loss: 0.7103 - val_accuracy: 0.6731\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8116 - val_loss: 0.7124 - val_accuracy: 0.6731\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8172 - val_loss: 0.7170 - val_accuracy: 0.6731\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8172 - val_loss: 0.7216 - val_accuracy: 0.6859\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.8199 - val_loss: 0.7209 - val_accuracy: 0.6923\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8283 - val_loss: 0.7199 - val_accuracy: 0.6923\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3702 - accuracy: 0.8227 - val_loss: 0.7308 - val_accuracy: 0.6923\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8366 - val_loss: 0.7196 - val_accuracy: 0.6987\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3566 - accuracy: 0.8338 - val_loss: 0.7282 - val_accuracy: 0.6987\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.8449 - val_loss: 0.7220 - val_accuracy: 0.6987\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.8476 - val_loss: 0.7232 - val_accuracy: 0.7051\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3356 - accuracy: 0.8449 - val_loss: 0.7281 - val_accuracy: 0.7051\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3303 - accuracy: 0.8615 - val_loss: 0.7257 - val_accuracy: 0.7115\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3245 - accuracy: 0.8560 - val_loss: 0.7302 - val_accuracy: 0.7115\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3138 - accuracy: 0.8698 - val_loss: 0.7247 - val_accuracy: 0.7051\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3068 - accuracy: 0.8698 - val_loss: 0.7238 - val_accuracy: 0.6859\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3022 - accuracy: 0.8698 - val_loss: 0.7244 - val_accuracy: 0.6859\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2935 - accuracy: 0.8726 - val_loss: 0.7243 - val_accuracy: 0.6795\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2887 - accuracy: 0.8920 - val_loss: 0.7212 - val_accuracy: 0.6859\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2822 - accuracy: 0.8726 - val_loss: 0.7272 - val_accuracy: 0.6859\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2798 - accuracy: 0.8975 - val_loss: 0.7261 - val_accuracy: 0.6859\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.9003 - val_loss: 0.7355 - val_accuracy: 0.6987\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2667 - accuracy: 0.8920 - val_loss: 0.7333 - val_accuracy: 0.7051\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2603 - accuracy: 0.8975 - val_loss: 0.7380 - val_accuracy: 0.6987\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2580 - accuracy: 0.8975 - val_loss: 0.7290 - val_accuracy: 0.7051\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.8947 - val_loss: 0.7303 - val_accuracy: 0.7051\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2468 - accuracy: 0.8975 - val_loss: 0.7347 - val_accuracy: 0.7051\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2392 - accuracy: 0.9003 - val_loss: 0.7421 - val_accuracy: 0.7051\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2358 - accuracy: 0.9030 - val_loss: 0.7387 - val_accuracy: 0.6987\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2298 - accuracy: 0.9141 - val_loss: 0.7386 - val_accuracy: 0.7115\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2255 - accuracy: 0.9114 - val_loss: 0.7348 - val_accuracy: 0.7115\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2236 - accuracy: 0.9197 - val_loss: 0.7291 - val_accuracy: 0.6987\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2192 - accuracy: 0.9169 - val_loss: 0.7385 - val_accuracy: 0.7115\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2137 - accuracy: 0.9197 - val_loss: 0.7318 - val_accuracy: 0.7115\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2070 - accuracy: 0.9197 - val_loss: 0.7365 - val_accuracy: 0.7244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2103 - accuracy: 0.9280 - val_loss: 0.7512 - val_accuracy: 0.7244\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2050 - accuracy: 0.9197 - val_loss: 0.7527 - val_accuracy: 0.7244\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1969 - accuracy: 0.9224 - val_loss: 0.7568 - val_accuracy: 0.7179\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1928 - accuracy: 0.9224 - val_loss: 0.7519 - val_accuracy: 0.7179\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1866 - accuracy: 0.9307 - val_loss: 0.7540 - val_accuracy: 0.7179\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1836 - accuracy: 0.9307 - val_loss: 0.7563 - val_accuracy: 0.7244\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1813 - accuracy: 0.9363 - val_loss: 0.7557 - val_accuracy: 0.7308\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.9280 - val_loss: 0.7589 - val_accuracy: 0.7244\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1726 - accuracy: 0.9363 - val_loss: 0.7534 - val_accuracy: 0.7244\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1684 - accuracy: 0.9418 - val_loss: 0.7595 - val_accuracy: 0.7179\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1682 - accuracy: 0.9391 - val_loss: 0.7608 - val_accuracy: 0.7244\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.9474 - val_loss: 0.7574 - val_accuracy: 0.7308\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1618 - accuracy: 0.9446 - val_loss: 0.7661 - val_accuracy: 0.7308\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.9418 - val_loss: 0.7587 - val_accuracy: 0.7308\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1536 - accuracy: 0.9529 - val_loss: 0.7658 - val_accuracy: 0.7308\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1527 - accuracy: 0.9501 - val_loss: 0.7684 - val_accuracy: 0.7372\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1508 - accuracy: 0.9446 - val_loss: 0.7661 - val_accuracy: 0.7372\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1464 - accuracy: 0.9529 - val_loss: 0.7703 - val_accuracy: 0.7372\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1439 - accuracy: 0.9474 - val_loss: 0.7748 - val_accuracy: 0.7244\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.9474 - val_loss: 0.7781 - val_accuracy: 0.7244\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.9474 - val_loss: 0.7825 - val_accuracy: 0.7436\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1344 - accuracy: 0.9529 - val_loss: 0.7848 - val_accuracy: 0.7308\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.9529 - val_loss: 0.7908 - val_accuracy: 0.7436\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1311 - accuracy: 0.9474 - val_loss: 0.7923 - val_accuracy: 0.7436\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1295 - accuracy: 0.9529 - val_loss: 0.7861 - val_accuracy: 0.7372\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.9474 - val_loss: 0.7727 - val_accuracy: 0.7436\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9584 - val_loss: 0.7833 - val_accuracy: 0.7436\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1222 - accuracy: 0.9529 - val_loss: 0.7891 - val_accuracy: 0.7436\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1208 - accuracy: 0.9529 - val_loss: 0.7930 - val_accuracy: 0.7436\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1204 - accuracy: 0.9612 - val_loss: 0.7986 - val_accuracy: 0.7436\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.9584 - val_loss: 0.7890 - val_accuracy: 0.7500\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.9640 - val_loss: 0.7996 - val_accuracy: 0.7500\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.9584 - val_loss: 0.8149 - val_accuracy: 0.7500\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1071 - accuracy: 0.9640 - val_loss: 0.8171 - val_accuracy: 0.7564\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9640 - val_loss: 0.8165 - val_accuracy: 0.7628\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1020 - accuracy: 0.9668 - val_loss: 0.8156 - val_accuracy: 0.7628\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1021 - accuracy: 0.9640 - val_loss: 0.8311 - val_accuracy: 0.7628\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1000 - accuracy: 0.9668 - val_loss: 0.8283 - val_accuracy: 0.7628\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0971 - accuracy: 0.9695 - val_loss: 0.8381 - val_accuracy: 0.7628\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0968 - accuracy: 0.9695 - val_loss: 0.8489 - val_accuracy: 0.7500\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9612 - val_loss: 0.8583 - val_accuracy: 0.7628\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1074 - accuracy: 0.9751 - val_loss: 0.8626 - val_accuracy: 0.7436\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0938 - accuracy: 0.9695 - val_loss: 0.8697 - val_accuracy: 0.7564\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9723 - val_loss: 0.8676 - val_accuracy: 0.7564\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9695 - val_loss: 0.8732 - val_accuracy: 0.7628\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0856 - accuracy: 0.9695 - val_loss: 0.8761 - val_accuracy: 0.7628\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9723 - val_loss: 0.8823 - val_accuracy: 0.7692\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9751 - val_loss: 0.8874 - val_accuracy: 0.7628\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9695 - val_loss: 0.8966 - val_accuracy: 0.7628\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9806 - val_loss: 0.8849 - val_accuracy: 0.7628\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9778 - val_loss: 0.9097 - val_accuracy: 0.7628\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0740 - accuracy: 0.9778 - val_loss: 0.9262 - val_accuracy: 0.7628\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0727 - accuracy: 0.9806 - val_loss: 0.9365 - val_accuracy: 0.7628\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0696 - accuracy: 0.9806 - val_loss: 0.9416 - val_accuracy: 0.7756\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.9834 - val_loss: 0.9504 - val_accuracy: 0.7756\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 0.9695 - val_loss: 0.9609 - val_accuracy: 0.7821\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0643 - accuracy: 0.9889 - val_loss: 0.9744 - val_accuracy: 0.7756\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0616 - accuracy: 0.9861 - val_loss: 0.9911 - val_accuracy: 0.7756\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0605 - accuracy: 0.9861 - val_loss: 0.9987 - val_accuracy: 0.7756\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0568 - accuracy: 0.9972 - val_loss: 1.0098 - val_accuracy: 0.7692\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.9917 - val_loss: 1.0202 - val_accuracy: 0.7692\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0560 - accuracy: 0.9889 - val_loss: 1.0316 - val_accuracy: 0.7692\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0559 - accuracy: 0.9917 - val_loss: 1.0380 - val_accuracy: 0.7756\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0557 - accuracy: 0.9834 - val_loss: 1.0522 - val_accuracy: 0.7756\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9945 - val_loss: 1.0598 - val_accuracy: 0.7756\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.9945 - val_loss: 1.0704 - val_accuracy: 0.7756\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9917 - val_loss: 1.0884 - val_accuracy: 0.7756\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.9889 - val_loss: 1.0831 - val_accuracy: 0.7692\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9917 - val_loss: 1.0913 - val_accuracy: 0.7692\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9889 - val_loss: 1.1037 - val_accuracy: 0.7756\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9972 - val_loss: 1.1121 - val_accuracy: 0.7692\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9917 - val_loss: 1.1210 - val_accuracy: 0.7692\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9972 - val_loss: 1.1287 - val_accuracy: 0.7692\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9972 - val_loss: 1.1451 - val_accuracy: 0.7692\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9945 - val_loss: 1.1450 - val_accuracy: 0.7692\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9917 - val_loss: 1.1389 - val_accuracy: 0.7564\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 0.9889 - val_loss: 1.1399 - val_accuracy: 0.7564\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9917 - val_loss: 1.1457 - val_accuracy: 0.7692\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9889 - val_loss: 1.1504 - val_accuracy: 0.7628\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9945 - val_loss: 1.1604 - val_accuracy: 0.7628\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9834 - val_loss: 1.1787 - val_accuracy: 0.7692\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9917 - val_loss: 1.1754 - val_accuracy: 0.7628\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9945 - val_loss: 1.1879 - val_accuracy: 0.7564\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.9972 - val_loss: 1.1898 - val_accuracy: 0.7628\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9972 - val_loss: 1.1997 - val_accuracy: 0.7564\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9917 - val_loss: 1.1995 - val_accuracy: 0.7564\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9945 - val_loss: 1.2102 - val_accuracy: 0.7564\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 0.9945 - val_loss: 1.2200 - val_accuracy: 0.7564\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9917 - val_loss: 1.2320 - val_accuracy: 0.7692\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9945 - val_loss: 1.2175 - val_accuracy: 0.7564\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 1.2317 - val_accuracy: 0.7564\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9972 - val_loss: 1.2378 - val_accuracy: 0.7564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ae94ce8ee0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.9246\n",
      "accuracy: 92.46%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
